{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Decision tree\n",
    "The decision tree distill data in to knowledge. with this, we can take a set of unfamiliar data and extract a set of rules which are often comparable to those given by human expert.\n",
    "There are three section in this chaptre:\n",
    "- methods to construct a tree(recursion)\n",
    "- metrics of measuring the algo's success\n",
    "- building a classifier and matplotlib it\n",
    "\n",
    "## procedures:\n",
    "- collect: any method\n",
    "- prepare: the decision tree need nominal values, so continuous values will need to be quantized.\n",
    "- analyse: any\n",
    "- train : construct a tree data structure\n",
    "- test : error rate\n",
    "- use : any supervised learning. OFTEN trees are used to better understand the data.\n",
    "\n",
    "\n",
    "## treeGenerate(D,A)\n",
    "\n",
    "```\n",
    "IF every item in the dataset is in the same class then:\n",
    "    return the class label\n",
    "Else choose the best feature to split the data\n",
    "     split the data\n",
    "     create a branch node\n",
    "         for each node, call self.func and add result to branch node\n",
    "         stop condition : - all instances have the same class (leaf node)\n",
    "                          - run out all the feature, take a majority vote                        \n",
    "return branch node\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the Shannon entropy of a dataset\n",
    "k : class label indice.  Ent: entropy ( the higher entropy, the more mixed up the data is)\n",
    "$$ Ent(D) = - \\sum_{k=1}^{\\| y \\|} p_k log_2 p_k $$\n",
    "* to calculate entropy, we ONLY need the labels and not the dataset\n",
    "#### informaton gain(C3.5)\n",
    "\n",
    "\n",
    "$$ Gain(D,a) = Ent(D) - \\sum_{v=1}^{V} \\frac {D^v}{D} Ent(D^v)$$\n",
    "$$choosen \\quad feature : a^* = \\underset{a \\in A}{\\arg\\min} Gain(D,a) $$\n",
    "\n",
    "#### Geni impurity (CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decision_tree\n",
    "tree1 = decision_tree.dt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the entropy of the above dataset is 0.970951\n"
     ]
    }
   ],
   "source": [
    "tree1.get_dataset([[1,1,'1'],[1,1,'1'],[1,0,'0'],[0,1,'0'],[0,0,'0']])\n",
    "labels = ['no surfacing','flippers']\n",
    "print('the entropy of the above dataset is %f' % tree1.ent(tree1.dataset))    #%d %f %s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the entropy of the above dataset is 1.370951\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1,1,'2'],[1,1,'1'],[1,0,'0'],[0,1,'0'],[0,0,'0']]\n",
    "print('the entropy of the above dataset is %f' % tree1.ent(dataset))    #%d %f %s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset splitting on a given feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [4, 5, 6]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append \n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "a.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extend\n",
    "a = [1,2,3]\n",
    "a.extend(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, '1'], [1, '1'], [0, '0']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=tree1.split(tree1.dataset,0,1)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best feature to split the above dataset is: 0\n"
     ]
    }
   ],
   "source": [
    "# select the best feature:\n",
    "indice = tree1.ft_eval(tree1.dataset) \n",
    "print('the best feature to split the above dataset is: %d' %indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
